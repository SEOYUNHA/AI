{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a10yxjEQocvy"
      },
      "source": [
        "### **Content License Agreement**\n",
        "\n",
        "<font color='red'><b>**WARNING**</b></font> : 본 자료는 삼성청년SW·AI아카데미의 컨텐츠 자산으로, 보안서약서에 의거하여 어떠한 사유로도 임의로 복사, 촬영, 녹음, 복제, 보관, 전송하거나 허가 받지 않은 저장매체를 이용한 보관, 제3자에게 누설, 공개 또는 사용하는 등의 무단 사용 및 불법 배포 시 법적 조치를 받을 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e256f743"
      },
      "source": [
        "# **Customer Service AI 에이전트 개발 : 에이전트 기반**\n",
        "\n",
        "## **1. 실습 개요**\n",
        "\n",
        "이번 단계에서는 고객 서비스 AI 에이전트를 고도화하여 복잡한 고객 민원을 처리하고 다른 시스템과도 소통 가능한 '똑똑한 민원 해결사 에이전트'를 개발하는 것을 목표로 합니다.\n",
        "\n",
        "## **2. 실습 진행 목적 및 배경**\n",
        "\n",
        "- 목적: 기본적인 고객 서비스 AI 에이전트의 기능을 확장하고, 추론/계획 능력(ReAct), 멀티턴 대화 처리(메모리), 그리고 성능 평가 개선 방법을 학습하여 실제 환경에서 복합적인 문제를 해결할 수 있는 에이전트 개발 역량을 키웁니다.\n",
        "- 배경: AI 온라인 서점의 CS 에이전트가 단순 문의를 넘어 배송 지연, 보상 요구 등 복합적인 고객 불만을 처리하는 시나리오를 통해 실질적인 에이전트 개발 과정을 체득합니다.\n",
        "\n",
        "## **3. 실습 수행으로 얻어갈 수 있는 역량**\n",
        "\n",
        "- AI 에이전트의 도구 활용 및 확장 능력 (Tool-learning, RAG)\n",
        "- 에이전트의 신뢰성 확보 방법 (Trustworthiness)\n",
        "- ReAct 프레임워크를 활용한 에이전트의 추론 및 계획 능력 향상\n",
        "- 멀티 에이전트 상호작용의 기초 이해\n",
        "- 멀티턴 대화를 위한 에이전트 메모리 기능 구현\n",
        "- 에이전트의 문제 해결 과정 논리성 기반 성능 평가 방법 학습 (Reward Model 개념)\n",
        "\n",
        "## **4. 실습 핵심 내용**\n",
        "\n",
        "- 보상 정책 RAG 확장 및 신뢰성 있는 쿠폰 발급 도구 개발\n",
        "- ReAct 프레임워크 적용을 위한 시스템 프롬프트 수정 및 Agent Thought/Action/Observation 과정 확인\n",
        "- BillingRequest Pydantic 모델 정의 및 JSON 출력 강제 방법 학습\n",
        "- Agent에 멀티턴 대화 메모리 기능 추가\n",
        "- 도구 사용 순서 기반의 Agent 성능 평가 함수 개선 및 시나리오별 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqf3GyoAo9ru"
      },
      "source": [
        "# **Prerequisites**\n",
        "\n",
        "코랩에서 기본적으로 설치된 라이브러리와 새로 설치하는 라이브리리 사이에서 발생하는 의존성 문제입니다. 이는 Python 패키지 관리 구조상, 특정 버전 조합이 완벽히 호환되지 않는 경우가 많기에 발생하고, 강의 실습에 큰 영향을 주지 않는 단순 Error이니 안심하고 실습을 진행해주셔도 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM77U5-EpANo",
        "outputId": "13c5c9cb-2f8c-494f-c712-ae715a04bf4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (0.3.79)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-1.0.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain_upstage\n",
            "  Downloading langchain_upstage-0.7.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.37)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.1)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting chromadb<2.0.0,>=1.0.20 (from langchain-chroma)\n",
            "  Downloading chromadb-1.2.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-chroma to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-chroma\n",
            "  Downloading langchain_chroma-0.2.6-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pypdf<5.0.0,>=4.2.0 (from langchain_upstage)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting tokenizers<0.21.0,>=0.20.0 (from langchain_upstage)\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.3.0)\n",
            "Collecting pybase64>=1.4.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.38.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.37.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.75.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.25.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers<0.21.0,>=0.20.0->langchain_upstage) (0.35.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain_upstage) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain_upstage) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain_upstage) (1.1.10)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.0.0)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.71.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (2.19.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.5.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain-chroma) (0.6.1)\n",
            "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-0.2.6-py3-none-any.whl (12 kB)\n",
            "Downloading langchain_upstage-0.7.4-py3-none-any.whl (25 kB)\n",
            "Downloading chromadb-1.2.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.7/20.7 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=82cfc68bce73bf5a3dda7b15a6ffe26f249457e3efa0938481fcf533dfe94f53\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pypdf, pybase64, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, humanfriendly, httptools, bcrypt, backoff, watchfiles, typing-inspect, requests, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-semantic-conventions, onnxruntime, dataclasses-json, tokenizers, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, chromadb, langchain_upstage, langchain-chroma, langchain-community\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "transformers 4.57.1 requires tokenizers<=0.23.0,>=0.22.0, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.2.2 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 langchain-chroma-0.2.6 langchain-community-0.3.31 langchain-openai-0.3.35 langchain_upstage-0.7.4 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypdf-4.3.1 pypika-0.48.9 requests-2.32.5 tokenizers-0.20.3 typing-inspect-0.9.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n",
            "Collecting pymupdf==1.26.3\n",
            "  Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.3-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.26.3\n"
          ]
        }
      ],
      "source": [
        "# 버전 명시\n",
        "!pip install langchain langchain-openai langchain-core langchain-community langchain-chroma langchain_upstage\n",
        "!pip install pymupdf==1.26.3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvVsaPqCS0VK",
        "outputId": "68c90a7f-b677-4040-c0ec-8f5af23627b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
            "  Downloading langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
            "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (0.4.37)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (4.15.0)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
            "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
            "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain) (3.0.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
            "  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain) (1.3.1)\n",
            "Downloading langchain-1.0.2-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.1-py3-none-any.whl (467 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.1/467.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-upstage 0.7.4 requires langchain-core<0.4.0,>=0.3.78, but you have langchain-core 1.0.1 which is incompatible.\n",
            "langchain-openai 0.3.35 requires langchain-core<1.0.0,>=0.3.78, but you have langchain-core 1.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-1.0.2 langchain-core-1.0.1 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 ormsgpack-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACfyPDRjTnOR",
        "outputId": "cf4203e9-e25a-4c1f-c6e1-696f741c5327"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 1.0.2\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://docs.langchain.com/\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: langchain-core, langgraph, pydantic\n",
            "Required-by: langchain-community\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1058df04"
      },
      "source": [
        "# **Exercise Overview**\n",
        "\n",
        "## **실습 목차**\n",
        "\n",
        "## 고객 서비스 AI 에이전트 레벨업\n",
        "\n",
        "## 목차\n",
        "\n",
        "1.  **프로젝트 2 개요 및 목표**\n",
        "    *   프로젝트 목표 및 시나리오 설명\n",
        "    *   핵심 학습 개념 및 챕터 4-1 과의 연관성\n",
        "2.  **실습 1: Agent의 도구 가방 채우기 (Tool-learning & Trustworthiness)**\n",
        "    *   학습 키워드 설명 (Tool-learning, RAG, Trustworthiness, Domain-specific agent)\n",
        "    *   정책 검색 도구 확장 (RAG)\n",
        "        *   `reward_policy.txt` 파일 준비\n",
        "        *   Vector Store 확장 및 검색 확인\n",
        "    *   불만 고객 쿠폰 발급 도구 개발 및 Trustworthiness 구현\n",
        "    *   개발된 도구 목록에 추가\n",
        "3.  **실습 2단계: 생각의 흐름 만들기 (Planning & Reasoning)**\n",
        "    *   학습 키워드 설명 (Reasoning, Planning, Action, ReAct)\n",
        "    *   ReAct 프레임워크 적용을 위한 시스템 프롬프트 수정\n",
        "    *   Agent 실행 및 '생각의 과정(Thought)' 로그 확인 방법 안내\n",
        "    *   멀티턴 대화를 위한 메모리 기능 추가\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu1WlLHprIli"
      },
      "source": [
        "# 환경 설정\n",
        "\n",
        "## UPSTAGE Credit 및 API Key 발급 받기\n",
        "\n",
        "1. 회원 가입 진행\n",
        "  1. <a href = \"https://console.upstage.ai/\">업스테이지 콘솔</a> 에 방문합니다.\n",
        "  2. 계정이 없다면, 구글 계정을 통해 회원가입을 진행합니다\n",
        "  3.  계정에 로그인 합니다.\n",
        "\n",
        "2. API Key 발급\n",
        "  1. <a href = \"https://console.upstage.ai/api-keys\">업스테이지 콘솔 - API Keys</a>페이지를 클릭합니다.\n",
        "  2. Create New key를 누르고, 발급받은 API key를 복사합니다.\n",
        "  3. 하단 셀을 실행한 후, 복사한 API Key를 넣습니다.\n",
        "  4. 세션 재시작시에는 업스테이지 api 를 사용하는 코드를 사용하기 위해 반드시 다시 설정해야 합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a6quh5xrHfA",
        "outputId": "e46f6fec-ca93-49f2-87e3-a8275011766d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Upstage API key: ··········\n",
            "API key has been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# @title set API key\n",
        "import os\n",
        "import getpass\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Get the Upstage API key using getpass\n",
        "if \"UPSTAGE_API_KEY\" not in os.environ or not os.environ[\"UPSTAGE_API_KEY\"]:\n",
        "    os.environ[\"UPSTAGE_API_KEY\"] = getpass.getpass(\"Enter your Upstage API key: \")\n",
        "\n",
        "print(\"API key has been set successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cacf284c"
      },
      "source": [
        "## Agent의 도구 가방 채우기 (Tool-learning & Trustworthiness)\n",
        "\n",
        "이번 실습에서는 우리 에이전트가 고객의 복잡한 민원을 해결하기 위해 사용할 새로운 도구들을 만들고, 이 도구들이 믿을 수 있게 작동하도록 '신뢰성(Trustworthiness)'이라는 개념을 적용해 볼 것입니다.\n",
        "\n",
        "### 학습 키워드 설명\n",
        "\n",
        "**Tool-learning (도구 학습)**\n",
        "\n",
        "Tool-learning은 에이전트가 외부 도구나 함수를 사용하는 방법을 배우는 능력을 말합니다. 마치 사람이 망치, 드라이버 같은 도구를 사용해서 어떤 작업을 하듯이, AI 에이전트도 특정 작업을 수행하기 위해 프로그래밍된 함수나 외부 시스템과 연동되는 도구를 사용할 수 있습니다. 에이전트는 사용자의 요청을 이해하고, 그 요청을 처리하기 위해 어떤 도구가 필요한지 스스로 판단하여 선택하고 사용하는 방법을 학습합니다. 이렇게 하면 에이전트가 자신의 학습 데이터에만 의존하지 않고, 실시간 정보에 접근하거나 특정 기능을 실행하는 등 더 다양하고 복잡한 작업을 수행할 수 있게 됩니다.\n",
        "\n",
        "**RAG (Retrieval-Augmented Generation, 검색 증강 생성)**\n",
        "\n",
        "RAG는 '검색(Retrieval)'과 '생성(Generation)'을 결합한 기술입니다. 에이전트가 질문을 받으면, 먼저 가지고 있는 문서나 데이터베이스에서 질문과 관련된 정보를 '검색(Retrieval)'합니다. 그리고 검색된 정보를 참고하여 가장 적절하고 정확한 답변을 '생성(Generation)'해 냅니다. 이렇게 하면 에이전트가 최신 정보나 특정 도메인(영역)의 전문 지식 없이도 정확한 답변을 할 수 있게 됩니다. 우리는 배송 정책이나 보상 정책 같은 회사 내부 문서를 RAG를 통해 에이전트에게 제공하여, 정책 관련 질문에 정확히 답변할 수 있도록 할 것입니다.\n",
        "\n",
        "**Trustworthiness (신뢰성)**\n",
        "\n",
        "Trustworthiness는 에이전트의 행동이 얼마나 믿을 수 있고 안전한지를 보장하는 개념입니다. 특히 에이전트가 실제 시스템에 영향을 미치는 도구(예: 쿠폰 발급, 주문 변경)를 사용할 때 매우 중요합니다. 신뢰성을 확보하기 위해 우리는 도구 사용 전에 특정 조건이 충족되는지 확인하는 로직을 추가할 수 있습니다. 예를 들어, 쿠폰 발급 도구는 '배송 지연' 상태인 주문에만 사용하도록 조건을 걸어, 에이전트가 실수로 정상적인 주문에 쿠폰을 발급하는 것을 막는 것입니다. 이는 에이전트가 예측 가능하고 안전하게 작동하도록 만듭니다.\n",
        "\n",
        "**Domain-specific agent (도메인 특화 에이전트)**\n",
        "\n",
        "Domain-specific agent는 특정 분야나 영역(도메인)에 대해 깊이 있는 지식과 기능을 갖춘 에이전트입니다. 예를 들어, 의료 분야 에이전트는 질병 진단이나 처방에 대한 전문 지식을 가지고 있고, 금융 분야 에이전트는 주식 거래나 투자 조언에 특화되어 있습니다. 우리가 만드는 고객 서비스 에이전트는 'AI 온라인 서점'이라는 도메인에 특화되어, 주문, 배송, 보상, 쿠폰 등 고객 서비스와 관련된 질문과 요청을 처리하는 데 필요한 지식과 도구를 갖추게 됩니다. 특정 도메인에 특화되면 해당 분야의 복잡한 문제도 더 정확하고 효율적으로 해결할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5b9882a"
      },
      "source": [
        "### 1-1 정책 검색 도구 확장 (RAG)\n",
        "\n",
        "이제 우리 에이전트의 지식 기반을 확장해 보겠습니다. Chapter 4-1 에서 배송 정책(`shipping_policy.txt`)으로 RAG를 구축했다면, 이번에는 보상 정책(`reward_policy.txt`)을 추가하여 에이전트가 배송뿐만 아니라 보상 및 보상 정책에 대해서도 정확하게 답변할 수 있도록 만들 것입니다.\n",
        "\n",
        "이를 위해 먼저 `reward_policy.txt` 파일을 생성하고, 그 내용을 로드하여 기존 배송 정책과 함께 벡터 스토어에 저장하는 과정을 거칩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50756587"
      },
      "source": [
        "#### `reward_policy.txt` 파일 준비\n",
        "\n",
        "YES24의 정책에 관한 PDF 문서에서 보상 정책만을 텍스트로 추출합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgPZQUyXBEOG",
        "outputId": "5f5d54cc-e34a-48ee-f7aa-8f74d99f3fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWEo-XdUBEOG"
      },
      "source": [
        "1. 코드를 실행하면 \"Go to this URL in a browser:\" 라는 메시지와 함께 링크가 나타납니다. 이 링크를 클릭하세요.\n",
        "2. Google 계정 선택 화면이 나타나면 Google Drive에 연결할 계정을 선택합니다.\n",
        "3. Google Drive 권한 요청 화면이 나타나면 \"허용\"을 클릭합니다.\n",
        "4. 인증 코드가 나타나면 이 코드를 복사합니다.\n",
        "5. Colab으로 돌아와 \"Enter your authorization code:\" 아래에 복사한 인증 코드를 붙여넣고 Enter 키를 누릅니다.\n",
        "\n",
        "정상적으로 마운트가 완료되면 `/content/drive` 경로를 통해 Google Drive에 접근할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyAFrf4wsuYb",
        "outputId": "79b794db-879a-4927-e477-e3ad0f5562d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing shipping_policy.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile shipping_policy.txt\n",
        "# AI 온라인 서점 배송 정책\n",
        "\n",
        "## 일반 배송\n",
        "- 평일 오후 3시 이전 주문 시 당일 발송됩니다.\n",
        "- 오후 3시 이후 주문 건은 익일 발송됩니다.\n",
        "- 주말 및 공휴일은 배송이 어렵습니다.\n",
        "\n",
        "## 도서 산간 지역 배송\n",
        "- 제주 및 도서 산간 지역은 추가 배송비가 발생할 수 있습니다.\n",
        "- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능합니다.\n",
        "\n",
        "## 배송 조회\n",
        "- 주문 번호 order-123의 배송 상태는 마이페이지에서 조회 가능합니다.\n",
        "- 회원 및 비회원 모두 주문 번호로 배송 조회가 가능합니다.\n",
        "- 배송 관련 문의는 고객센터로 연락 주시기 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrufiKmy1UsV",
        "outputId": "060216b8-261b-4f9f-d412-dedaff4d6476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- './' 경로에서 찾은 PDF 파일 목록: [] ---\n",
            "'./shipping_policy.txt' 파일 로드 완료. 1 문서 로드됨.\n",
            "\n",
            "--- 모든 파일에서 로드된 총 문서 정보 ---\n",
            "총 문서 개수: 1\n",
            "첫 번째 문서 내용 (일부): # AI 온라인 서점 배송 정책\n",
            "\n",
            "## 일반 배송\n",
            "- 평일 오후 3시 이전 주문 시 당일 발송됩니다.\n",
            "- 오후 3시 이후 주문 건은 익일 발송됩니다.\n",
            "- 주말 및 공휴일은 배송이 어렵습니다.\n",
            "\n",
            "## 도서 산간 지역 배송\n",
            "- 제주 및 도서 산간 지역은 추가 배송비가 발생할 수 있습니다.\n",
            "- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능합니다.\n",
            "\n",
            "## ...\n",
            "첫 번째 문서 메타데이터: {'source': './shipping_policy.txt'}\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "import glob # 파일을 검색하기 위한 glob 모듈을 가져옵니다.\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "# './' 경로에 있는 모든 PDF 파일을 찾습니다.\n",
        "pdf_files = glob.glob('?')\n",
        "\n",
        "all_documents = [] # 모든 PDF 파일에서 로드된 문서를 저장할 빈 리스트를 생성합니다.\n",
        "\n",
        "print(f\"--- './' 경로에서 찾은 PDF 파일 목록: {pdf_files} ---\")\n",
        "\n",
        "# 찾은 각 PDF 파일에 대해 로드 및 파싱을 수행합니다.\n",
        "for pdf_filepath in pdf_files:\n",
        "    try:\n",
        "        loader = PyMuPDFLoader(pdf_filepath)\n",
        "        pages = loader.load()\n",
        "        all_documents.extend(pages) # 로드된 페이지들을 all_documents 리스트에 추가합니다.\n",
        "        print(f\"'{pdf_filepath}' 파일 로드 완료. {len(pages)} 페이지 로드됨.\")\n",
        "    except Exception as e:\n",
        "        print(f\"'{pdf_filepath}' 파일 로드 중 오류 발생: {e}\")\n",
        "\n",
        "# shipping_policy.txt 파일도 로드하여 all_documents에 추가합니다.\n",
        "shipping_policy_file_path = './shipping_policy.txt'\n",
        "\n",
        "try:\n",
        "    # Create a TextLoader instance with the file path\n",
        "    loader = TextLoader(shipping_policy_file_path)\n",
        "\n",
        "    # Load the document\n",
        "    text_documents = loader.load()\n",
        "\n",
        "    # Extend all_documents with text file documents\n",
        "    all_documents.extend(text_documents)\n",
        "    print(f\"'{shipping_policy_file_path}' 파일 로드 완료. {len(text_documents)} 문서 로드됨.\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {shipping_policy_file_path}. Please ensure the file exists at this location.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading {shipping_policy_file_path}: {e}\")\n",
        "\n",
        "\n",
        "# 모든 로드된 총 문서(PDF 페이지 + Text 문서) 정보 출력\n",
        "print(\"\\n--- 모든 파일에서 로드된 총 문서 정보 ---\")\n",
        "print(f\"총 문서 개수: {len(all_documents)}\")\n",
        "if all_documents:\n",
        "    print(f\"첫 번째 문서 내용 (일부): {all_documents[0].page_content[:200]}...\")\n",
        "    print(f\"첫 번째 문서 메타데이터: {all_documents[0].metadata}\")\n",
        "else:\n",
        "    print(\"로드된 문서가 없습니다.\")\n",
        "print(\"-\" * 20)\n",
        "\n",
        "# 다음 단계를 위해 변수 이름을 'documents'로 맞춥니다.\n",
        "documents = all_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpSpY9AeDbvV",
        "outputId": "8ee8534e-433d-4478-ac99-e249a8b938f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "프롬프트 확인\n",
            "\n",
            "--- Upstage LLM을 사용하여 보상 정책 추출 시작 ---\n",
            "문서에 '보상 정책'과 관련된 내용이 없습니다. 제공된 문서에서는 'AI 온라인 서점 배송 정책'에 대한 설명이 포함되어 있지만, 보상 절차, 조건, 예외 사항 등 보상과 관련된 정보는 없습니다.\n",
            "보상 정책 추출 완료 (Upstage LLM). 추출된 내용 일부:\n",
            "문서에 '보상 정책'과 관련된 내용이 없습니다. 제공된 문서에서는 'AI 온라인 서점 배송 정책'에 대한 설명이 포함되어 있지만, 보상 절차, 조건, 예외 사항 등 보상과 관련된 정보는 없습니다....\n",
            "----------------------------------------------------\n",
            "`reward_policy.txt` 파일이 추출된 보상 정책 내용으로 생성되었습니다.\n",
            "\n",
            "'reward_policy.txt' 파일 로드 완료. 1 문서 로드됨.\n",
            "--- 로드된 보상 정책 내용 확인 ---\n",
            "문서에 '보상 정책'과 관련된 내용이 없습니다. 제공된 문서에서는 'AI 온라인 서점 배송 정책'에 대한 설명이 포함되어 있지만, 보상 절차, 조건, 예외 사항 등 보상과 관련된 정보는 없습니다.\n",
            "-----------------------------\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리를 임포트합니다.\n",
        "from langchain_upstage import ChatUpstage\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Upstage LLM 인스턴스를 생성합니다.\n",
        "# API 키는 환경 변수 UPSTAGE_API_KEY에 설정되어 있어야 합니다.\n",
        "# 모델 이름은 필요에 따라 변경하세요 (예: \"solar-1-mini-128k-instruct\")\n",
        "llm_upstage = ChatUpstage()\n",
        "\n",
        "# LLM에게 보상 정책을 추출하도록 요청하는 프롬프트를 구성합니다.\n",
        "# 모든 문서 내용을 하나의 문자열로 합치거나, 각 문서별로 LLM을 호출할 수 있습니다.\n",
        "# 여기서는 간단하게 문서 내용을 합쳐서 프롬프트에 넣습니다.\n",
        "all_document_content = \"\\n---\\n\".join([doc.page_content for doc in documents])\n",
        "\n",
        "# LLM 프롬프트 정의\n",
        "# LLM에게 문서 내용에서 보상 정책만 명확하게 추출하도록 지시합니다.\n",
        "extraction_prompt_template = \"\"\"다음은 다양한 정책 내용이 포함된 문서입니다.\n",
        "이 문서에서 '보상 정책'과 관련된 내용은 모두 추출하여 정리해 주세요.\n",
        "추출된 내용 외의 다른 설명이나 서론/결론은 포함하지 마세요.\n",
        "보상 절차, 보상 조건, 보상 예외 사항 등 보상과 관련된 모든 정보를 포함해야 합니다.\n",
        "\n",
        "문서 내용:\n",
        "---\n",
        "{document_content}\n",
        "---\n",
        "\n",
        "추출된 보상 정책:\n",
        "\"\"\"\n",
        "\n",
        "# 프롬프트에 문서 내용을 채웁니다.\n",
        "extraction_prompt = extraction_prompt_template.format(document_content=all_document_content)\n",
        "print('프롬프트 확인')\n",
        "print(\"\\n--- Upstage LLM을 사용하여 보상 정책 추출 시작 ---\")\n",
        "\n",
        "extracted_reward_policy = \"\"\n",
        "try:\n",
        "    # LLM 호출하여 보상 정책 추출\n",
        "    # 긴 문서 내용의 경우, 청킹하여 각 청크별로 추출하거나 요약하는 방식이 더 효율적일 수 있습니다.\n",
        "    # 여기서는 간단하게 전체 내용을 전달합니다 (모델의 컨텍스트 창 크기 고려 필요).\n",
        "    llm_response = llm_upstage.invoke(extraction_prompt)\n",
        "    print(llm_response.content )\n",
        "    extracted_reward_policy = llm_response.content# 응답 객체에서 내용 추출\n",
        "\n",
        "    print(\"보상 정책 추출 완료 (Upstage LLM). 추출된 내용 일부:\")\n",
        "    print(extracted_reward_policy[:500] + \"...\") # 내용 일부 출력\n",
        "    print(\"----------------------------------------------------\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Upstage LLM 호출 중 오류 발생: {e}\")\n",
        "    extracted_reward_policy = \"보상 정책 추출 실패.\"\n",
        "\n",
        "\n",
        "# --- 추출된 내용을 `reward_policy.txt` 파일로 저장 ---\n",
        "\n",
        "# 추출된 보상 정책 내용을 `reward_policy.txt` 파일에 씁니다.\n",
        "reward_policy_file_path = \"reward_policy.txt\"\n",
        "if extracted_reward_policy and extracted_reward_policy != \"보상 정책 추출 실패.\":\n",
        "    with open(reward_policy_file_path, \"w\", encoding='utf-8') as f: # 인코딩 지정\n",
        "        f.write(extracted_reward_policy)\n",
        "    print(f\"`{reward_policy_file_path}` 파일이 추출된 보상 정책 내용으로 생성되었습니다.\")\n",
        "else:\n",
        "    print(f\"추출된 보상 정책 내용이 없거나 추출에 실패하여 `{reward_policy_file_path}` 파일을 생성하지 않았습니다.\")\n",
        "\n",
        "\n",
        "# --- `reward_policy.txt` 파일 로드 및 내용 확인 ---\n",
        "\n",
        "# reward_policy.txt 파일 로드\n",
        "try:\n",
        "    # Create a TextLoader instance with the file path\n",
        "    loader = TextLoader(reward_policy_file_path, encoding='utf-8') # 인코딩 지정\n",
        "\n",
        "    # Load the document\n",
        "    reward_docs = loader.load()\n",
        "    print(f\"\\n'{reward_policy_file_path}' 파일 로드 완료. {len(reward_docs)} 문서 로드됨.\")\n",
        "\n",
        "    if reward_docs:\n",
        "        print(\"--- 로드된 보상 정책 내용 확인 ---\")\n",
        "        print(reward_docs[0].page_content)\n",
        "        print(\"-----------------------------\")\n",
        "    else:\n",
        "        print(\"로딩된 보상 정책 문서가 비어 있습니다.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {reward_policy_file_path}. Please ensure the file exists after extraction.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading or processing {reward_policy_file_path}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "501616f9"
      },
      "source": [
        "#### Vector Store 확장 및 검색 확인\n",
        "\n",
        "이제 준비된 `reward_policy.txt` 파일과 기존 `shipping_policy.txt` 파일을 함께 로드하여 RAG의 핵심인 Vector Store를 확장합니다. Vector Store는 문서를 임베딩(Embeddings, 벡터 변환)하여 저장해두는 곳으로, 검색 시 사용자의 질문을 벡터로 변환한 후 이 저장소에서 가장 유사한 문서 벡터를 찾아냅니다.\n",
        "\n",
        "- RecursiveCharacterTextSplitter 를 사용하여 200자로 40자씩 겹치게 분리하여 chunk를 생성\n",
        "- UpstageEnbedding을 사용하여 임베딩 벡터를 생성\n",
        "- 생성된 embedding을 chroma 에 저장\n",
        "\n",
        "\n",
        "**참고:**\n",
        "\n",
        "*   **파싱(Parsing):** 비정형 데이터를 구조화된 형태로 변환하는 과정입니다. 여기서는 텍스트 파일의 내용을 읽어오는 것을 포함합니다.\n",
        "*   **청킹(Chunking):** 긴 문서를 의미 있는 작은 단위(청크)로 나누는 과정입니다. RAG에서는 검색 및 임베딩 효율성을 위해 문서를 청크로 나눕니다. `CharacterTextSplitter`는 문자를 기준으로 청크를 나눕니다.\n",
        "*   **임베딩(Embedding):** 텍스트를 컴퓨터가 이해할 수 있는 숫자 벡터로 변환하는 과정입니다. 의미적으로 유사한 텍스트는 유사한 벡터 값을 가집니다. `OpenAIEmbeddings`와 같은 임베딩 모델이 이 역할을 합니다.\n",
        "*   **인덱싱(Indexing):** 검색을 빠르게 할 수 있도록 데이터를 정리하고 색인을 만드는 과정입니다. Vector Store에 문서를 저장할 때 내부적으로 인덱싱이 수행됩니다.\n",
        "*   **검색기(Retriever):** 사용자의 질문과 가장 관련성이 높은 문서 청크를 Vector Store에서 찾아주는 역할을 합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.text import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_upstage import UpstageEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# 문서 로드\n",
        "# TextLoader를 사용하여 텍스트 파일의 내용을 불러옵니다.\n",
        "shipping_loader = TextLoader(\"./shipping_policy.txt\", encoding=\"utf-8\")\n",
        "shipping_docs = shipping_loader.load()\n",
        "\n",
        "reward_loader = TextLoader(\"./reward_policy.txt\", encoding=\"utf-8\")\n",
        "reward_docs = reward_loader.load()\n",
        "\n",
        "all_docs = shipping_docs + reward_docs\n",
        "\n",
        "print(\"--- 원본 문서 ---\")\n",
        "print(all_docs)\n",
        "\n",
        "# 문서를 청크 단위로 분할\n",
        "# CharacterTextSplitter를 사용하여 문자를 기준으로 청크를 나눕니다.\n",
        "# chunk_size: 각 청크의 최대 문자 수\n",
        "# chunk_overlap: 인접한 청크 간에 겹치는 문자 수 (검색 시 문맥 유지를 위해 사용)\n",
        "\n",
        "# 2. Split: 문서를 200자 단위로 자르기 (엔터 단위, 40자씩 겹치게)\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=40,\n",
        "    length_function=len,\n",
        ")\n",
        "chunks = splitter.split_documents(all_docs)\n",
        "\n",
        "print(\"\\n--- 200자 단위로 잘린 문서 조각(Chunk)들 ---\")\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"[Chunk {i+1}]\")\n",
        "    print(chunk.page_content)\n",
        "    print()\n",
        "\n",
        "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
        "\n",
        "# 잘라낸 문서 조각(chunks)들을 임베딩하여 Vector DB에 저장합니다.\n",
        "vector_store = Chroma.from_documents(chunks, embeddings)\n",
        "\n",
        "vector_store.add_documents(chunks)\n",
        "print(\"Chunk들을 Vector DB에 저장 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfXppCsJXO5Q",
        "outputId": "9c8871cc-a48e-4c09-9bf8-cdcc13ba5b2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 원본 문서 ---\n",
            "[Document(metadata={'source': './shipping_policy.txt'}, page_content='# AI 온라인 서점 배송 정책\\n\\n## 일반 배송\\n- 평일 오후 3시 이전 주문 시 당일 발송됩니다.\\n- 오후 3시 이후 주문 건은 익일 발송됩니다.\\n- 주말 및 공휴일은 배송이 어렵습니다.\\n\\n## 도서 산간 지역 배송\\n- 제주 및 도서 산간 지역은 추가 배송비가 발생할 수 있습니다.\\n- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능합니다.\\n\\n## 배송 조회\\n- 주문 번호 order-123의 배송 상태는 마이페이지에서 조회 가능합니다.\\n- 회원 및 비회원 모두 주문 번호로 배송 조회가 가능합니다.\\n- 배송 관련 문의는 고객센터로 연락 주시기 바랍니다.\\n'), Document(metadata={'source': './reward_policy.txt'}, page_content=\"문서에 '보상 정책'과 관련된 내용이 없습니다. 제공된 문서에서는 'AI 온라인 서점 배송 정책'에 대한 설명이 포함되어 있지만, 보상 절차, 조건, 예외 사항 등 보상과 관련된 정보는 없습니다.\")]\n",
            "\n",
            "--- 200자 단위로 잘린 문서 조각(Chunk)들 ---\n",
            "[Chunk 1]\n",
            "# AI 온라인 서점 배송 정책\n",
            "\n",
            "## 일반 배송\n",
            "- 평일 오후 3시 이전 주문 시 당일 발송됩니다.\n",
            "- 오후 3시 이후 주문 건은 익일 발송됩니다.\n",
            "- 주말 및 공휴일은 배송이 어렵습니다.\n",
            "\n",
            "## 도서 산간 지역 배송\n",
            "- 제주 및 도서 산간 지역은 추가 배송비가 발생할 수 있습니다.\n",
            "- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능합니다.\n",
            "\n",
            "[Chunk 2]\n",
            "## 배송 조회\n",
            "- 주문 번호 order-123의 배송 상태는 마이페이지에서 조회 가능합니다.\n",
            "- 회원 및 비회원 모두 주문 번호로 배송 조회가 가능합니다.\n",
            "- 배송 관련 문의는 고객센터로 연락 주시기 바랍니다.\n",
            "\n",
            "[Chunk 3]\n",
            "문서에 '보상 정책'과 관련된 내용이 없습니다. 제공된 문서에서는 'AI 온라인 서점 배송 정책'에 대한 설명이 포함되어 있지만, 보상 절차, 조건, 예외 사항 등 보상과 관련된 정보는 없습니다.\n",
            "\n",
            "Chunk들을 Vector DB에 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 검색기 테스트\n"
      ],
      "metadata": {
        "id": "hSeUzSRVenHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "# 보상 정책 관련 질문으로 검색 테스트\n",
        "reward_query = \"배송 지연 보상 정책이 어떻게 되나요?\"\n",
        "\n",
        "print(f\"\\n'{reward_query}' 검색 결과:\")\n",
        "retrieved_docs = retriever.invoke(reward_query)\n",
        "print(f\"\\n[검색 결과]:\\n{retrieved_docs[0].page_content}\")\n",
        "\n",
        "# 배송 정책 관련 질문으로 검색 테스트\n",
        "shipping_query = \"배송은 얼마나 걸리나요?\"\n",
        "print(f\"\\n'{shipping_query}' 검색 결과:\")\n",
        "retrieved_docs = retriever.invoke(shipping_query)\n",
        "print(f\"\\n[검색 결과]:\\n{retrieved_docs[0].page_content}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WACxeCTuejB8",
        "outputId": "e0889fc7-6314-4e1b-a0d1-8e7e4bfb28cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'배송 지연 보상 정책이 어떻게 되나요?' 검색 결과:\n",
            "\n",
            "[검색 결과]:\n",
            "문서에 '보상 정책'과 관련된 내용이 없습니다. 제공된 문서에서는 'AI 온라인 서점 배송 정책'에 대한 설명이 포함되어 있지만, 보상 절차, 조건, 예외 사항 등 보상과 관련된 정보는 없습니다.\n",
            "\n",
            "'배송은 얼마나 걸리나요?' 검색 결과:\n",
            "\n",
            "[검색 결과]:\n",
            "# AI 온라인 서점 배송 정책\n",
            "\n",
            "## 일반 배송\n",
            "- 평일 오후 3시 이전 주문 시 당일 발송됩니다.\n",
            "- 오후 3시 이후 주문 건은 익일 발송됩니다.\n",
            "- 주말 및 공휴일은 배송이 어렵습니다.\n",
            "\n",
            "## 도서 산간 지역 배송\n",
            "- 제주 및 도서 산간 지역은 추가 배송비가 발생할 수 있습니다.\n",
            "- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_order_status(order_id: str):\n",
        "    \"\"\"\n",
        "    주문 ID를 받아 현재 배송 상태를 반환하는 도구입니다.\n",
        "    실제 애플리케이션에서는 외부 주문 관리 시스템에 쿼리할 것입니다.\n",
        "    \"\"\"\n",
        "    # 시연을 위해 특정 주문 ID에 대해 미리 정해진 상태를 반환합니다.\n",
        "    if order_id == \"ORDER123\":\n",
        "        return \"Delivered\" # 배송 완료\n",
        "    elif order_id == \"ORDER456\":\n",
        "        return \"Shipping Delayed\" # 배송 지연\n",
        "    elif order_id == \"ORDER789\":\n",
        "        return \"Processing\" # 처리 중\n",
        "    else:\n",
        "        return \"Order Not Found\" # 주문 찾을 수 없음\n",
        "\n",
        "    print(f\"모의: 주문 ID {order_id} 상태 확인 중\")\n",
        "    # 실제 시나리오에서는 외부 API를 호출합니다.\n",
        "    # status = external_api.get_status(order_id)\n",
        "    # return status"
      ],
      "metadata": {
        "id": "QoFNyJNseP_M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d2486d4"
      },
      "source": [
        "### 1-2 불만 고객 쿠폰 발급 도구 개발 및 Trustworthiness 구현\n",
        "\n",
        "이제 고객의 불만 사항에 대해 보상을 제공할 수 있는 새로운 도구를 만듭니다. 바로 '불만 고객 쿠폰 발급 도구'입니다. 이 도구는 특정 주문 ID에 대해 할인 쿠폰을 발급하는 역할을 합니다.\n",
        "\n",
        "여기서 중요한 것은 '신뢰성(Trustworthiness)' 개념을 적용하는 것입니다. 우리는 에이전트가 아무 주문에나 쿠폰을 남발하는 것을 막아야 합니다. 따라서 이 도구는 쿠폰을 발급하기 전에 반드시 해당 주문의 상태를 확인하고, '배송 지연'과 같이 쿠폰 발급 조건에 맞는 경우에만 실제로 쿠폰을 발급하도록 로직을 추가할 것입니다. `get_order_status` 함수를 활용하여 주문 상태를 확인하는 것이 신뢰성 구현의 핵심입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c334e53",
        "outputId": "b1493985-b4c4-421a-97b8-f77066f3f738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`issue_complaint_coupon` 도구 함수 개발 완료 (Trustworthiness 로직 포함).\n",
            "\n",
            "--- 쿠폰 발급 도구 테스트 ---\n",
            "쿠폰 발급 시도 중: 주문 ID ORDER456\n",
            "모의: 지연된 주문 ID ORDER456에 대해 쿠폰 발급 완료.\n",
            "주문 ID ORDER456 쿠폰 발급 결과: 주문 ID ORDER456에 대해 5,000원 할인 쿠폰이 발급되었습니다.\n",
            "쿠폰 발급 시도 중: 주문 ID ORDER123\n",
            "모의: 주문 ID ORDER123 상태 'Delivered'는 쿠폰 발급 대상이 아닙니다.\n",
            "주문 ID ORDER123 쿠폰 발급 결과: 주문 ID ORDER123는 쿠폰 발급 대상이 아닙니다. 현재 상태: Delivered\n",
            "쿠폰 발급 시도 중: 주문 ID ORDER_UNKNOWN\n",
            "모의: 주문 ID ORDER_UNKNOWN 상태 'Order Not Found'는 쿠폰 발급 대상이 아닙니다.\n",
            "주문 ID ORDER_UNKNOWN 쿠폰 발급 결과: 주문 ID ORDER_UNKNOWN는 쿠폰 발급 대상이 아닙니다. 현재 상태: Order Not Found\n",
            "--- 쿠폰 발급 도구 테스트 완료 ---\n"
          ]
        }
      ],
      "source": [
        "# 4. 불만 고객 쿠폰 발급 도구 개발 및 Trustworthiness 구현\n",
        "\n",
        "# issue_complaint_coupon 함수를 정의합니다.\n",
        "# 이 함수는 주문 ID를 입력받아 쿠폰 발급 로직을 수행합니다.\n",
        "def issue_complaint_coupon(order_id: str):\n",
        "    \"\"\"\n",
        "    지정된 주문 ID에 대해 불만 고객 쿠폰을 발급하는 도구입니다.\n",
        "    Trustworthiness 로직이 포함되어 있어 주문 상태가 'Shipping Delayed'일 때만 쿠폰을 발급합니다.\n",
        "    \"\"\"\n",
        "    print(f\"쿠폰 발급 시도 중: 주문 ID {order_id}\")\n",
        "\n",
        "    # Trustworthiness 구현: get_order_status 도구를 사용하여 주문 상태를 확인합니다.\n",
        "    order_status = get_order_status(order_id) # 이전에 정의한 get_order_status 함수 호출\n",
        "\n",
        "    # 주문 상태가 'Shipping Delayed'인지 확인합니다.\n",
        "    if order_status == \"Shipping Delayed\":\n",
        "        # 상태가 '배송 지연'이면 쿠폰 발급 메시지를 반환합니다.\n",
        "        # 실제 시나리오에서는 외부 시스템에 쿠폰 발급 요청을 보낼 것입니다.\n",
        "        print(f\"모의: 지연된 주문 ID {order_id}에 대해 쿠폰 발급 완료.\")\n",
        "        return f\"주문 ID {order_id}에 대해 5,000원 할인 쿠폰이 발급되었습니다.\"\n",
        "    else:\n",
        "        # 그 외의 상태이면 쿠폰 발급 대상이 아님을 알립니다.\n",
        "        print(f\"모의: 주문 ID {order_id} 상태 '{order_status}'는 쿠폰 발급 대상이 아닙니다.\")\n",
        "        return f\"주문 ID {order_id}는 쿠폰 발급 대상이 아닙니다. 현재 상태: {order_status}\"\n",
        "\n",
        "print(\"`issue_complaint_coupon` 도구 함수 개발 완료 (Trustworthiness 로직 포함).\")\n",
        "\n",
        "# 개발된 도구 테스트 (Trustworthiness 로직 확인)\n",
        "print(\"\\n--- 쿠폰 발급 도구 테스트 ---\")\n",
        "# 배송 지연 상태인 주문 테스트\n",
        "test_order_delayed = \"ORDER456\"\n",
        "coupon_result_delayed = issue_complaint_coupon(test_order_delayed)\n",
        "print(f\"주문 ID {test_order_delayed} 쿠폰 발급 결과: {coupon_result_delayed}\")\n",
        "\n",
        "# 배송 완료 상태인 주문 테스트\n",
        "test_order_delivered = \"ORDER123\"\n",
        "coupon_result_delivered = issue_complaint_coupon(test_order_delivered)\n",
        "print(f\"주문 ID {test_order_delivered} 쿠폰 발급 결과: {coupon_result_delivered}\")\n",
        "\n",
        "# 존재하지 않는 주문 테스트\n",
        "test_order_unknown = \"ORDER_UNKNOWN\"\n",
        "coupon_result_unknown = issue_complaint_coupon(test_order_unknown)\n",
        "print(f\"주문 ID {test_order_unknown} 쿠폰 발급 결과: {coupon_result_unknown}\")\n",
        "print(\"--- 쿠폰 발급 도구 테스트 완료 ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df583910"
      },
      "source": [
        "### 1-3 개발된 도구 목록에 추가\n",
        "\n",
        "이제 우리가 만든 새로운 도구들을 Agent가 사용할 수 있도록 도구 목록에 추가할 차례입니다. LangChain의 `Tool` 클래스를 사용하여 각 함수를 Agent가 이해하고 사용할 수 있는 '도구' 객체로 감싸고, 이들을 리스트로 관리합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "# 5. 개발된 도구 목록에 추가\n",
        "\n",
        "@tool\n",
        "def rag_tool(query: str) -> str:\n",
        "    \"\"\"배송 정책, 보상 정책, 환불 정책 등 AI 온라인 서점의 다양한 정책 문서에서 고객 질문과 관련된 정보를 검색합니다.\n",
        "    이 도구는 특정 정책 내용 (예: 배송 기간, 보상 조건, 환불 절차)에 대한 고객의 질문에 답변하기 위해 사용하세요.\n",
        "    입력은 검색하고자 하는 정책에 대한 구체적인 자연어 질문이어야 합니다.\n",
        "    예시 입력: \"배송 지연 시 보상 정책이 어떻게 되나요?\", \"환불 절차를 알려주세요.\", \"무료 배송 조건은 무엇인가요?\"\n",
        "    \"\"\"\n",
        "\n",
        "    results = retriever.invoke(query)\n",
        "    if not results:\n",
        "        return \"관련 문서를 찾지 못했습니다.\"\n",
        "    top_docs = \"\\n\".join([doc.page_content for doc in results])\n",
        "    return f\"검색된 문서:\\n{top_docs}\"\n",
        "\n",
        "# 불만 고객 쿠폰 발급 함수를 Agent 도구로 정의합니다.\n",
        "coupon_tool = Tool(\n",
        "    name=\"Issue_Complaint_Coupon\", # 도구의 이름\n",
        "    func=issue_complaint_coupon, # 쿠폰 발급 함수를 연결\n",
        "    description=\"\"\"고객의 주문이 특정 조건(예: 배송 지연)을 만족하는 경우, 해당 주문 ID에 대해 불만 고객 쿠폰을 발급합니다.\n",
        "    **이 도구는 반드시 'Get Order Status' 도구를 사용하여 고객의 주문 상태를 확인한 결과가 'Shipping Delayed' 일 때만 사용해야 합니다.**\n",
        "    주문 상태가 'Shipping Delayed'가 아닌 경우에는 절대 이 도구를 사용해서는 안 됩니다.\n",
        "    이 도구를 사용하기 전에 고객의 주문 ID를 명확히 파악해야 합니다.\n",
        "    입력은 쿠폰을 발급할 **단일 주문 ID** 여야 합니다.\n",
        "    예시 입력: \"ORDER456\"\n",
        "    \"\"\"\n",
        "    # description에 도구 사용 조건을 명확히 제시하여 에이전트의 Trustworthiness 로직 이해를 돕습니다.\n",
        ")\n",
        "\n",
        "# Chapter 4-1에서 만든 get_order_status 함수도 도구로 추가합니다.\n",
        "order_status_tool = Tool(\n",
        "    name=\"Get_Order_Status\", # 도구의 이름\n",
        "    func=get_order_status, # 주문 상태 확인 함수 연결\n",
        "    description=\"\"\"주어진 주문 ID에 대한 현재 배송 상태를 검색합니다.\n",
        "    고객이 특정 주문의 배송 상태를 문의하거나, 쿠폰 발급 등 주문 상태 확인이 필요한 작업을 수행하기 전에 **반드시** 이 도구를 사용하여 주문 상태를 확인해야 합니다.\n",
        "    이 도구는 항상 정확한 최신 주문 상태 정보를 반환합니다.\n",
        "    입력은 상태를 확인하고자 하는 **단일 주문 ID** 여야 합니다.\n",
        "    예시 입력: \"ORDER123\", \"ORDER789\"\n",
        "    반환값은 'Delivered', 'Shipping Delayed', 'Processing', 'Order Not Found' 중 하나입니다.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "# Agent가 사용할 수 있는 전체 도구 목록을 리스트로 관리합니다.\n",
        "agent_tools = [rag_tool, coupon_tool, order_status_tool]\n",
        "\n",
        "\n",
        "print(\"\\n개발된 RAG 도구와 쿠폰 발급 도구가 `agent_tools` 목록에 추가되었습니다.\")\n",
        "print(f\"현재 Agent 도구 목록: {[tool.name for tool in agent_tools]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8MCuCE_j6Sb",
        "outputId": "819821ce-266f-4bb1-b993-99651ee0601b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "개발된 RAG 도구와 쿠폰 발급 도구가 `agent_tools` 목록에 추가되었습니다.\n",
            "현재 Agent 도구 목록: ['rag_tool', 'Issue_Complaint_Coupon', 'Get_Order_Status']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf1f1eb1"
      },
      "source": [
        "## 생각의 흐름 만들기 (Planning & Reasoning)\n",
        "\n",
        "현재 Agent는 질문을 받으면 바로 도구를 사용하려고 할 수 있습니다. 하지만 복잡한 민원(예: 배송 지연 불만 및 보상 요구)을 해결하려면 단순히 도구를 사용하는 것을 넘어, 문제 상황을 분석하고, 해결을 위한 단계를 스스로 생각하며(Reasoning), 어떤 도구를 어떤 순서로 사용할지 계획(Planning)을 세우는 과정이 필요합니다.\n",
        "\n",
        "이번 실습에서는 LangChain의 ReAct(Reason+Act) 프레임워크를 적용하여 Agent에게 '생각하는 능력'을 부여하고, 문제 해결을 위한 논리적인 흐름을 따르도록 가이드하는 방법을 배웁니다. ReAct는 생각(Thought)과 행동(Action)을 번갈아 수행하며 목표를 달성하는 방식입니다.\n",
        "\n",
        "### 학습 키워드 설명\n",
        "\n",
        "**Reasoning (추론)**\n",
        "\n",
        "Reasoning은 에이전트가 주어진 정보(사용자 요청, 도구 결과 등)를 바탕으로 논리적인 판단을 내리고 결론을 도출하는 과정입니다. 고객의 요청의 진짜 의도가 무엇인지 파악하고, 어떤 정보가 부족하며, 다음 단계로 무엇을 해야 할지 스스로 생각하는 능력입니다. ReAct 프레임워크에서 'Thought' 부분이 바로 이 추론 과정에 해당합니다.\n",
        "\n",
        "**Planning (계획 수립)**\n",
        "\n",
        "Planning은 에이전트가 추론을 통해 파악한 목표를 달성하기 위해 구체적인 행동 순서, 즉 계획을 세우는 과정입니다. 어떤 도구를 먼저 사용하고, 그 결과에 따라 다음 도구를 어떻게 사용할지 등 일련의 절차를 설계합니다. 복잡한 문제를 해결하기 위해서는 효과적인 계획 수립이 필수적입니다.\n",
        "\n",
        "**Action (행동)**\n",
        "\n",
        "Action은 계획에 따라 에이전트가 실제로 특정 도구를 사용하거나 외부 시스템과 상호작용하는 실행 단계입니다. 예를 들어, '주문 상태 확인' 도구를 사용하거나 '쿠폰 발급' 도구를 실행하는 것이 Action입니다. Action을 실행한 결과는 'Observation'(관찰 결과)으로 에이전트에게 돌아오며, 에이전트는 이 Observation을 바탕으로 다음 Thought와 Action을 결정합니다.\n",
        "\n",
        "**ReAct (Reasoning and Acting, 추론 및 행동)**\n",
        "\n",
        "ReAct는 Reasoning(추론)과 Acting(행동)을 반복적으로 수행하며 목표를 달성하는 에이전트 프레임워크입니다. 에이전트는 사용자 요청을 받으면 먼저 **Thought**(생각)를 통해 상황을 분석하고 다음에 할 행동을 결정합니다. 그리고 결정한 **Action**(행동)을 실행합니다. Action의 결과로 **Observation**(관찰)을 얻게 되고, 이 Observation을 바탕으로 다시 **Thought**를 하여 다음 Action을 결정합니다. 이 과정을 목표 달성 시까지 반복하여, 동적으로 문제를 해결해 나갑니다. 이는 에이전트가 미리 정해진 규칙만 따르는 것이 아니라, 상황에 맞춰 유연하게 대처할 수 있게 해줍니다.\n",
        "\n",
        "ReAct 흐름 요약:\n",
        "사용자 요청 -> 계획수립 -> Thought -> Action -> Observation -> Thought -> Action -> Observation -> ... -> Thought -> Final Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTf-4zJtBEOK"
      },
      "source": [
        "## 메모리 붙이기\n",
        "\n",
        "CS Agent는 고객의 요청을 직접 처리하는 것 외에도, 다른 시스템이나 에이전트와 협력해야 할 때가 있습니다. 예를 들어, 고객에게 보상을 제공하기로 결정했다면, 실제 쿠폰을 발급하거나 보상을 처리하는 시스템에 이 정보를 전달해야 합니다. 또한, 고객과의 대화가 여러 번 오가더라도 이전 내용을 기억하고 맥락을 유지하는 것이 중요합니다.\n",
        "\n",
        "이번 실습에서는 다음 두 가지 주요 목표를 달성합니다:\n",
        "\n",
        "1.  **멀티턴 대화 기능 추가 (메모리):** Agent가 이전 대화 내용을 기억하여 사용자와의 상호작용에서 연속성을 갖도록 메모리 기능을 Agent에 통합합니다.\n",
        "\n",
        "### 학습 키워드 설명\n",
        "\n",
        "**Memory (메모리)**\n",
        "\n",
        "AI 에이전트에서 메모리는 이전 대화 내용을 저장하고 관리하는 기능입니다. 사람이 대화할 때 앞서 나눈 이야기를 기억하고 그 맥락 위에서 다음 대화를 이어가듯이, 에이전트도 메모리를 통해 사용자와의 과거 상호작용 기록(질문, 답변, 도구 사용 결과 등)을 참고하여 현재의 요청을 더 정확하게 이해하고 적절히 응답할 수 있습니다. 메모리가 없으면 에이전트는 매번 새로운 질문을 받을 때마다 이전의 모든 내용을 잊어버리고 처음부터 다시 시작해야 하므로 자연스럽고 효율적인 대화가 어렵습니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from langchain.agents.middleware import SummarizationMiddleware    # 요약 기능추가\n",
        "from langchain.agents import create_agent\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.tools import tool\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "# =====================================================\n",
        "# 시스템 프롬프트\n",
        "# =====================================================\n",
        "SYSTEM_PROMPT = \"\"\"너는 고객 상담용 AI 챗봇이야\n",
        "사용자의 질문이 제품 배송, 운영시간, 서비스 정책과 관련되어 있다면\n",
        "search_docs 도구를 한 번만 사용해서 관련 정보를 찾아 답변해줘.\n",
        "도구를 사용하지 않아도 충분하면 직접 대답해도 좋아.\n",
        "\n",
        "**각 도구의 사용 조건과 설명을 반드시 따르세요.**\n",
        "\n",
        "*   특히, **'Issue Complaint Coupon' 도구**는 고객의 주문 상태를 **'Get Order Status' 도구를 사용하여 확인한 결과가 'Shipping Delayed'일 때만 사용해야 합니다.** 주문 상태가 'Shipping Delayed'가 아닌 경우에는 이 도구를 사용해서는 안 됩니다.\n",
        "*   'Policy Search' 도구는 배송 정책, 보상 정책 등 특정 정책 정보가 필요할 때 사용하며, 질문 형식으로 입력합니다.\n",
        "*   'Get Order Status' 도구는 고객이 특정 주문의 상태를 문의할 때 사용하며, 주문 ID를 입력합니다.\n",
        "\n",
        "\"\"\"\n",
        "key = os.environ.get(\"UPSTAGE_API_KEY\")\n",
        "# =====================================================\n",
        "# 모델 설정\n",
        "# =====================================================\n",
        "# model = init_chat_model(\"openai:gpt-4o-mini\")\n",
        "model = init_chat_model(base_url=\"https://api.upstage.ai/v1\", model_provider=\"openai\", model=\"solar-pro2\", api_key=key)\n",
        "# =====================================================\n",
        "# 최종 결과 포맷\n",
        "# =====================================================\n",
        "@dataclass\n",
        "class ResponseFormat:\n",
        "    answer: str   # AI의 대답 문장\n",
        "\n",
        "# =====================================================\n",
        "# 멀티턴을 위한 InMemorySaver\n",
        "# =====================================================\n",
        "checkpointer = InMemorySaver()\n",
        "\n",
        "# =====================================================\n",
        "# Agent 생성 (이곳에 SummarizationMiddleware를 설치합니다.)\n",
        "# =====================================================\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        "    tools=agent_tools,\n",
        "    response_format=ResponseFormat,\n",
        "    middleware=[\n",
        "    SummarizationMiddleware(\n",
        "        model=model, # 요약을 담당할 모델\n",
        "        max_tokens_before_summary=4000,  # 최대 4000 토큰으로 요약합니다.\n",
        "        messages_to_keep=20,  # 요약 이후 최대 20 메세지는 유지합니다.\n",
        "    )],\n",
        "    checkpointer=checkpointer\n",
        ")\n",
        "\n",
        "# =====================================================\n",
        "# 실행 예시 (이쁘게 출력하려는 노력입니다.)\n",
        "# =====================================================\n",
        "def print_message(msgs):\n",
        "    for msg in msgs:\n",
        "        if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
        "            for tool_call in msg.tool_calls:\n",
        "                name = tool_call.get(\"name\")\n",
        "                args = tool_call.get(\"args\")\n",
        "                if name == \"ResponseFormat\":\n",
        "                    continue\n",
        "                print(f\"💭( 🛠️{name} 함수 호출 {args} )\")\n",
        "\n",
        "        if \"AIMessage\" not in str(type(msg)):\n",
        "            print(f\"💭( {type(msg).__name__} : {msg.content!r} )\")\n",
        "\n",
        "# =============================================\n",
        "# 대화 루프 (멀티턴)\n",
        "# =============================================\n",
        "print(\"AI Agent 챗봇에 오신 걸 환영합니다!\")\n",
        "print(\"대화를 종료하려면 'bye'를 입력하세요.\\n\")\n",
        "print(f\"🤖 AI Agent : 무엇이든 질문하세요\")\n",
        "\n",
        "# thread_id를 통해 대화 세션 유지 (필수)\n",
        "config = {\"configurable\":{\"thread_id\": \"kfc_user\"}}\n",
        "\n",
        "while True:\n",
        "    print()\n",
        "    user_input = input(\"👤 인간 : \")\n",
        "\n",
        "    response = agent.invoke({\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ]},config = config) # thread_id 단위로 대화 상태 저장\n",
        "\n",
        "    print_message(response[\"messages\"][1:-1])\n",
        "    print(f\"🤖 AI Agent : {response[\"structured_response\"].answer}\")\n",
        "\n",
        "    if user_input == 'bye':\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdC-zXoBnny8",
        "outputId": "44967422-52cf-4da6-d788-5a8f62b22ee7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Agent 챗봇에 오신 걸 환영합니다!\n",
            "대화를 종료하려면 'bye'를 입력하세요.\n",
            "\n",
            "🤖 AI Agent : 무엇이든 질문하세요\n",
            "\n",
            "👤 인간 : 안녕\n",
            "🤖 AI Agent : 안녕하세요! 무엇을 도와드릴까요? 😊\n",
            "\n",
            "👤 인간 : 배송\n",
            "💭( ToolMessage : \"Returning structured response: ResponseFormat(answer='안녕하세요! 무엇을 도와드릴까요? 😊')\" )\n",
            "💭( HumanMessage : '배송' )\n",
            "💭( 🛠️rag_tool 함수 호출 {'query': '배송 정책을 알려주세요.'} )\n",
            "💭( ToolMessage : \"검색된 문서:\\n# AI 온라인 서점 배송 정책\\n\\n## 일반 배송\\n- 평일 오후 3시 이전 주문 시 당일 발송됩니다.\\n- 오후 3시 이후 주문 건은 익일 발송됩니다.\\n- 주말 및 공휴일은 배송이 어렵습니다.\\n\\n## 도서 산간 지역 배송\\n- 제주 및 도서 산간 지역은 추가 배송비가 발생할 수 있습니다.\\n- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능합니다.\\n# AI 온라인 서점 배송 정책\\n\\n## 일반 배송\\n- 평일 오후 3시 이전 주문 시 당일 발송됩니다.\\n- 오후 3시 이후 주문 건은 익일 발송됩니다.\\n- 주말 및 공휴일은 배송이 어렵습니다.\\n\\n## 도서 산간 지역 배송\\n- 제주 및 도서 산간 지역은 추가 배송비가 발생할 수 있습니다.\\n- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능합니다.\\n문서에 '보상 정책'과 관련된 내용이 없습니다. 제공된 문서에서는 'AI 온라인 서점 배송 정책'에 대한 설명이 포함되어 있지만, 보상 절차, 조건, 예외 사항 등 보상과 관련된 정보는 없습니다.\\n문서에 '보상 정책'과 관련된 내용이 없습니다. 제공된 문서에서는 'AI 온라인 서점 배송 정책'에 대한 설명이 포함되어 있지만, 보상 절차, 조건, 예외 사항 등 보상과 관련된 정보는 없습니다.\" )\n",
            "🤖 AI Agent : AI 온라인 서점의 배송 정책을 안내해 드리겠습니다.\n",
            "\n",
            "**일반 배송**\n",
            "- 평일 오후 3시 이전 주문 시 당일 발송\n",
            "- 오후 3시 이후 주문 건은 익일 발송\n",
            "- 주말 및 공휴일은 배송 불가\n",
            "\n",
            "**도서 산간 지역 배송**\n",
            "- 제주 및 도서 산간 지역 추가 배송비 발생 가능\n",
            "- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능\n",
            "\n",
            "👤 인간 : bye\n",
            "💭( ToolMessage : \"Returning structured response: ResponseFormat(answer='안녕하세요! 무엇을 도와드릴까요? 😊')\" )\n",
            "💭( HumanMessage : '배송' )\n",
            "💭( 🛠️rag_tool 함수 호출 {'query': '배송 정책을 알려주세요.'} )\n",
            "💭( ToolMessage : \"검색된 문서:\\n# AI 온라인 서점 배송 정책\\n\\n## 일반 배송\\n- 평일 오후 3시 이전 주문 시 당일 발송됩니다.\\n- 오후 3시 이후 주문 건은 익일 발송됩니다.\\n- 주말 및 공휴일은 배송이 어렵습니다.\\n\\n## 도서 산간 지역 배송\\n- 제주 및 도서 산간 지역은 추가 배송비가 발생할 수 있습니다.\\n- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능합니다.\\n# AI 온라인 서점 배송 정책\\n\\n## 일반 배송\\n- 평일 오후 3시 이전 주문 시 당일 발송됩니다.\\n- 오후 3시 이후 주문 건은 익일 발송됩니다.\\n- 주말 및 공휴일은 배송이 어렵습니다.\\n\\n## 도서 산간 지역 배송\\n- 제주 및 도서 산간 지역은 추가 배송비가 발생할 수 있습니다.\\n- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능합니다.\\n문서에 '보상 정책'과 관련된 내용이 없습니다. 제공된 문서에서는 'AI 온라인 서점 배송 정책'에 대한 설명이 포함되어 있지만, 보상 절차, 조건, 예외 사항 등 보상과 관련된 정보는 없습니다.\\n문서에 '보상 정책'과 관련된 내용이 없습니다. 제공된 문서에서는 'AI 온라인 서점 배송 정책'에 대한 설명이 포함되어 있지만, 보상 절차, 조건, 예외 사항 등 보상과 관련된 정보는 없습니다.\" )\n",
            "💭( ToolMessage : \"Returning structured response: ResponseFormat(answer='AI 온라인 서점의 배송 정책을 안내해 드리겠습니다.\\\\n\\\\n**일반 배송**\\\\n- 평일 오후 3시 이전 주문 시 당일 발송\\\\n- 오후 3시 이후 주문 건은 익일 발송\\\\n- 주말 및 공휴일은 배송 불가\\\\n\\\\n**도서 산간 지역 배송**\\\\n- 제주 및 도서 산간 지역 추가 배송비 발생 가능\\\\n- 추가 배송비 및 예상 소요 시간은 주문 시 확인 가능')\" )\n",
            "💭( HumanMessage : 'bye' )\n",
            "🤖 AI Agent : 안녕히 가세요! 😊\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "304de928"
      },
      "source": [
        "### 멀티턴 대화를 위한 Agent 메모리 기능 추가\n",
        "\n",
        "Agent가 사용자와의 대화 맥락을 유지하려면 이전 대화 내용을 '기억'해야 합니다. LangChain에서는 다양한 메모리 타입을 제공하며, 그 중 `ConversationBufferMemory`는 대화 기록 전체를 버퍼에 저장하는 간단한 메모리 구현체입니다.\n",
        "\n",
        "이 실습에서는 `ConversationBufferMemory`를 사용하여 Agent 실행 체인에 메모리를 추가하고, 멀티턴 대화 테스트를 통해 Agent가 이전 대화를 기억하는지 확인합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMjxLDV8qeop"
      },
      "source": [
        "# 실습 마무리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ea68f15"
      },
      "source": [
        "이번 \"**고객 서비스 AI 에이전트 레벨업**\" 실습을 통해 다음과 같은 핵심 개념과 기술들을 학습했습니다.\n",
        "\n",
        "*   **Tool-learning (도구 학습):** Agent에게 외부 함수나 시스템과 상호작용할 수 있는 도구를 제공하고 사용하는 방법을 배웠습니다. (정책 검색, 쿠폰 발급 도구)\n",
        "*   **RAG (검색 증강 생성):** 외부 문서(정책 파일)를 Agent의 지식 기반으로 확장하고, 이를 바탕으로 정확한 답변을 생성하는 방법을 이해했습니다. (정책 검색 도구 확장)\n",
        "*   **Trustworthiness (신뢰성):** Agent가 민감한 도구(예: 쿠폰 발급)를 사용할 때 특정 조건을 확인하여 안전하고 신뢰할 수 있게 작동하도록 제어하는 로직을 구현했습니다.\n",
        "*   **ReAct (Reasoning and Acting):** Agent가 Thought(추론), Action(행동), Observation(관찰 결과) 단계를 반복하며 복잡한 문제를 해결하는 논리적인 사고 과정을 시스템 프롬프트를 통해 유도하는 방법을 학습했습니다.\n",
        "*   **Planning & Reasoning:** ReAct 프레임워크를 통해 Agent가 스스로 문제 해결을 위한 계획을 세우고 추론하는 능력을 향상시키는 개념을 체득했습니다.\n",
        "*   **Memory (메모리):** Agent가 이전 대화 내용을 기억하여 멀티턴 대화의 맥락을 유지하고 자연스러운 상호작용을 할 수 있도록 메모리 기능을 Agent 실행 체인에 통합했습니다.\n",
        "*   **Agent 성능 평가:** Agent의 문제 해결 과정, 특히 도구 사용의 논리적 순서를 기반으로 Agent의 성능을 평가하는 접근 방식(Reward Model 개념 연결)을 살펴보았습니다.\n",
        "\n",
        "이 실습을 통해 여러분은 기본적인 AI 에이전트가 실제 서비스 환경에서 복합적인 고객 민원을 처리하고, 외부 시스템과 협력하며, 대화 맥락을 유지하는 '똑똑한' 에이전트로 발전하는 과정에 대해 이해하셨기를 바랍니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}